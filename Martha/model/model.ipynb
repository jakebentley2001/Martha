{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Load CLIP model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Define food categories\n",
    "food_categories = [\"pizza\", \"sushi\", \"burger\"]  # expand as needed\n",
    "text = [f\"a photo of {category}\" for category in food_categories]\n",
    "\n",
    "# Process image and text\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get classification results\n",
    "logits_per_image = outputs.logits_per_image\n",
    "probs = logits_per_image.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 00:44:34.767322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2c2acdd52d4a8eb0d4c09cb6db4b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6343d2b3a204d9aace6aa0e51101895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e4d91837704ca2a71011c593ae97ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2e668392dd40fb93238d6c58b28c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0b08bc8cb141439ec9c3eaf05cbf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820e42a834594221996c191141c8828c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5a800ad2724b76bf1a17efada5caca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf7b9acedb44b42abb32c15fd9e0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Load CLIP model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPModel(\n",
      "  (text_model): CLIPTextTransformer(\n",
      "    (embeddings): CLIPTextEmbeddings(\n",
      "      (token_embedding): Embedding(49408, 512)\n",
      "      (position_embedding): Embedding(77, 512)\n",
      "    )\n",
      "    (encoder): CLIPEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x CLIPEncoderLayer(\n",
      "          (self_attn): CLIPSdpaAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): CLIPMLP(\n",
      "            (activation_fn): QuickGELUActivation()\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (vision_model): CLIPVisionTransformer(\n",
      "    (embeddings): CLIPVisionEmbeddings(\n",
      "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "      (position_embedding): Embedding(50, 768)\n",
      "    )\n",
      "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (encoder): CLIPEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x CLIPEncoderLayer(\n",
      "          (self_attn): CLIPSdpaAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): CLIPMLP(\n",
      "            (activation_fn): QuickGELUActivation()\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
      "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"openai/clip-vit-base-patch32\",\n",
      "  \"architectures\": [\n",
      "    \"CLIPModel\"\n",
      "  ],\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"logit_scale_init_value\": 2.6592,\n",
      "  \"model_type\": \"clip\",\n",
      "  \"projection_dim\": 512,\n",
      "  \"text_config\": {\n",
      "    \"bos_token_id\": 0,\n",
      "    \"dropout\": 0.0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"model_type\": \"clip_text_model\"\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"vision_config\": {\n",
      "    \"dropout\": 0.0,\n",
      "    \"model_type\": \"clip_vision_model\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPProcessor:\n",
      "- image_processor: CLIPImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "- tokenizer: CLIPTokenizerFast(name_or_path='openai/clip-vit-base-patch32', vocab_size=49408, model_max_length=77, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"processor_class\": \"CLIPProcessor\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'pixel_values'])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Example image\n",
    "url = \"https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Example text\n",
    "text = [\"A diagram\", \"A dog\", \"A cat\"]\n",
    "\n",
    "# Process the inputs\n",
    "inputs = processor(text=text, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Inspect the processed inputs\n",
    "print(inputs.keys())  # Keys: 'input_ids', 'pixel_values', 'attention_mask'\n",
    "print(inputs[\"pixel_values\"].shape)  # Shape of the processed image tensor\n",
    "print(inputs[\"input_ids\"].shape)  # Shape of the processed text tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPOutput(loss=None, logits_per_image=tensor([[25.0325, 19.4092, 18.5067]], grad_fn=<TBackward0>), logits_per_text=tensor([[25.0325],\n",
      "        [19.4092],\n",
      "        [18.5067]], grad_fn=<MulBackward0>), text_embeds=tensor([[ 0.0046, -0.0005,  0.0042,  ..., -0.0558, -0.0108, -0.0416],\n",
      "        [ 0.0127,  0.0020, -0.0256,  ..., -0.0393, -0.0300,  0.0158],\n",
      "        [ 0.0180, -0.0185, -0.0139,  ..., -0.0410, -0.0514,  0.0054]],\n",
      "       grad_fn=<DivBackward0>), image_embeds=tensor([[ 3.6206e-02, -1.3802e-02,  2.3978e-02, -1.3260e-02, -1.0139e-02,\n",
      "         -1.2517e-02,  1.4617e-02,  1.8685e-02,  4.3012e-02, -1.6747e-03,\n",
      "         -4.4739e-02, -8.2093e-04, -2.7760e-02,  4.2459e-02,  5.4218e-03,\n",
      "         -3.1072e-02, -2.5679e-02,  4.3092e-02, -3.9669e-02,  1.8438e-02,\n",
      "          2.2241e-02, -7.6318e-03,  1.1148e-02, -1.9530e-02, -6.0867e-02,\n",
      "          6.3376e-02, -1.9704e-02,  2.0494e-02, -4.7292e-04, -2.7398e-02,\n",
      "          2.6197e-02,  1.9112e-02, -1.2564e-03,  7.2394e-02,  1.4215e-02,\n",
      "         -6.8572e-03,  1.4663e-02,  2.5369e-02, -4.9503e-03, -1.8423e-01,\n",
      "         -1.1390e-02,  4.5191e-02, -2.9522e-02, -3.5041e-02, -3.5035e-02,\n",
      "         -3.6723e-02, -2.9829e-02,  6.5108e-03, -3.5146e-02, -2.2528e-02,\n",
      "          1.1643e-02, -2.4232e-02, -1.7690e-02,  6.2749e-02,  1.2955e-02,\n",
      "         -2.3237e-02,  2.6209e-03,  2.8564e-02, -1.9128e-02,  5.3407e-02,\n",
      "          5.7281e-02, -9.0291e-03,  1.4257e-02, -1.6539e-02,  2.5716e-03,\n",
      "          1.8187e-02,  2.3753e-02,  4.8600e-02, -1.2632e-02, -3.2163e-02,\n",
      "         -2.1298e-02, -1.3527e-02, -1.0651e-02,  5.1228e-02,  2.1756e-02,\n",
      "         -5.0518e-02, -8.4318e-03, -1.1047e-02, -1.4497e-02, -2.3772e-02,\n",
      "         -2.6655e-02,  2.9320e-02, -3.9760e-02,  6.3645e-02,  1.6170e-02,\n",
      "          3.0719e-02,  1.2668e-01,  8.2283e-03,  3.7256e-02, -2.3048e-02,\n",
      "          3.0225e-02, -5.9178e-03, -5.7078e-01,  2.2453e-02,  1.8314e-02,\n",
      "          8.0581e-03, -1.7821e-03, -4.2428e-02,  2.3978e-02, -2.3708e-02,\n",
      "         -3.3535e-02, -4.1035e-03, -2.7244e-02, -1.7386e-02,  2.1961e-02,\n",
      "         -2.8386e-02, -3.1178e-01,  4.5746e-02,  7.9728e-04, -4.2768e-06,\n",
      "          2.4199e-02, -4.9386e-02, -5.0451e-03, -5.8673e-03, -4.9301e-02,\n",
      "          2.7061e-02,  1.0187e-02, -7.7868e-02,  2.3776e-02,  2.4310e-02,\n",
      "         -1.4272e-02, -1.8275e-02, -4.9604e-03,  5.0730e-03,  1.1382e-02,\n",
      "          3.8945e-02,  1.1156e-02, -8.4655e-03,  2.1919e-02,  1.9323e-02,\n",
      "          5.7457e-02, -1.1137e-02,  3.2591e-03,  8.0716e-02,  6.0687e-03,\n",
      "          4.7318e-03, -2.2994e-02, -6.8774e-02,  8.5662e-04,  9.2092e-03,\n",
      "          1.9630e-02,  9.8558e-04, -6.8177e-02, -3.1912e-02, -2.3451e-02,\n",
      "          3.8915e-02, -1.3479e-02,  4.4100e-02, -3.8212e-03, -1.7095e-02,\n",
      "         -1.0541e-02,  2.4699e-02, -1.8071e-02, -1.0703e-02,  4.5342e-03,\n",
      "          5.2835e-03, -3.0492e-02, -1.8055e-02,  2.1968e-03,  1.5474e-02,\n",
      "          6.1102e-02, -1.6052e-02,  1.0389e-02, -4.2960e-02,  5.3098e-02,\n",
      "         -9.7703e-03,  2.1218e-02,  9.2502e-03, -1.1553e-02, -3.5201e-04,\n",
      "         -2.1150e-02, -1.8629e-02,  2.2514e-03, -4.2130e-02, -3.3649e-02,\n",
      "          3.1430e-02, -6.8670e-02,  4.4819e-02, -1.8360e-02,  4.9451e-02,\n",
      "         -1.2383e-02, -5.8001e-02, -4.8198e-02,  1.1365e-02, -1.5411e-02,\n",
      "         -2.3871e-02,  2.1860e-02,  4.6161e-02, -2.3113e-02,  3.4577e-04,\n",
      "         -1.8731e-02, -1.3845e-02,  1.2625e-02, -4.6936e-03, -4.2061e-02,\n",
      "         -2.9996e-02,  2.0814e-02,  2.2361e-02, -2.3796e-02, -1.8307e-03,\n",
      "          3.3272e-02, -2.8998e-02, -1.4716e-03, -5.8919e-02,  3.6489e-02,\n",
      "         -6.2832e-03, -2.5282e-02,  2.6894e-02,  2.4481e-02,  7.0897e-03,\n",
      "         -2.1059e-02, -6.8371e-02,  1.7090e-03,  1.0500e-02, -1.1170e-02,\n",
      "         -1.8460e-02,  3.3511e-02,  3.6781e-02, -1.7694e-02,  3.2883e-03,\n",
      "         -2.2782e-02,  4.2953e-02,  8.6529e-03, -5.1474e-03, -6.9160e-03,\n",
      "         -4.5189e-02,  3.8550e-02, -1.4824e-02, -1.4462e-02,  3.1227e-02,\n",
      "         -1.9816e-02,  5.0549e-02, -1.3361e-02,  2.4132e-02, -3.1729e-02,\n",
      "         -1.8215e-02, -1.3980e-02, -7.4361e-04, -1.4501e-02,  5.8754e-03,\n",
      "         -5.1098e-02, -1.2228e-02,  2.1561e-02,  2.0330e-02, -3.2237e-02,\n",
      "          5.7832e-02,  4.2096e-02,  2.4520e-02,  3.6305e-02,  2.6885e-02,\n",
      "         -1.3077e-05, -8.4232e-03, -2.1620e-02,  5.4850e-03, -1.0439e-02,\n",
      "          4.7584e-02, -2.7836e-02, -1.0143e-02, -1.3165e-01,  2.4679e-02,\n",
      "         -2.4235e-02,  2.2899e-02,  1.6818e-02,  5.0845e-02, -3.2899e-02,\n",
      "          2.2529e-02, -3.5123e-02, -5.1362e-02, -1.2732e-02, -1.1427e-02,\n",
      "         -2.3813e-02, -6.3734e-04, -4.9450e-03,  2.7847e-02,  3.1652e-02,\n",
      "          3.4113e-02,  4.9346e-03,  1.7692e-02, -6.9128e-03,  5.4005e-02,\n",
      "          3.1548e-02, -3.1424e-02, -3.5888e-02, -9.4584e-03, -1.9806e-03,\n",
      "          2.2996e-02,  1.0598e-02, -8.1615e-03,  2.6805e-03, -6.9487e-03,\n",
      "          1.9738e-02, -8.7111e-04, -1.1798e-02, -3.5663e-03,  2.4182e-02,\n",
      "          2.3815e-02, -2.9908e-03, -4.2568e-02, -9.8887e-03, -2.5312e-03,\n",
      "          3.0353e-02, -2.9733e-02, -3.3390e-02,  1.6830e-02, -4.3728e-03,\n",
      "         -4.9821e-02,  3.1076e-02,  8.5135e-03,  6.5958e-02,  3.5892e-02,\n",
      "         -6.6172e-02, -1.1403e-02,  8.0605e-02,  2.3865e-02, -3.3293e-02,\n",
      "         -1.2510e-02,  2.3302e-02,  2.4126e-02,  1.5520e-02,  3.8838e-02,\n",
      "          6.8750e-02,  1.6652e-01, -7.2462e-03,  4.0896e-02, -7.4841e-02,\n",
      "         -1.5135e-02, -5.0864e-02, -3.1421e-02,  3.3457e-03,  1.4029e-02,\n",
      "          2.9911e-02,  4.4381e-02,  4.7586e-02, -2.6461e-02, -2.9719e-03,\n",
      "          2.7898e-02,  2.0695e-02,  1.5531e-02,  7.4415e-03, -9.8748e-03,\n",
      "         -2.1302e-03, -4.1700e-02,  2.9423e-02,  4.7998e-04, -1.2636e-02,\n",
      "         -2.2599e-02,  1.2897e-02,  7.7315e-03,  1.3338e-02,  2.8812e-02,\n",
      "         -6.2586e-03, -2.3900e-02, -6.6385e-04,  2.9202e-03, -2.4759e-02,\n",
      "          3.1185e-02,  3.6559e-02, -2.2135e-02, -3.1614e-02,  4.8580e-02,\n",
      "         -9.9911e-03, -2.5730e-02,  3.0549e-02, -2.3418e-02, -9.0505e-02,\n",
      "          4.5470e-02, -1.0679e-02, -8.6642e-02,  2.6567e-02,  2.5662e-02,\n",
      "         -3.9872e-02, -7.1534e-03,  5.3515e-02,  7.2974e-03, -1.2308e-02,\n",
      "         -4.8822e-03, -3.5680e-03,  2.2713e-02, -5.3888e-02, -3.9699e-02,\n",
      "         -1.4955e-02, -2.9297e-02, -2.2271e-02,  2.6174e-02,  2.2010e-03,\n",
      "         -8.0619e-03,  1.0726e-02, -6.5325e-02,  1.8833e-02,  1.3292e-01,\n",
      "         -2.6068e-02,  4.9738e-02,  1.2517e-02,  8.2454e-03,  2.9570e-02,\n",
      "          1.7727e-04, -1.8030e-02, -4.5739e-02, -4.6595e-02, -8.0115e-03,\n",
      "          5.1476e-02,  8.8425e-03, -9.0273e-03,  1.9890e-03,  2.1778e-02,\n",
      "         -2.2393e-02, -4.5222e-02, -4.2274e-03,  7.1390e-02, -2.9886e-02,\n",
      "          3.2614e-02, -3.0693e-02,  6.0611e-03,  2.7867e-02,  2.5911e-02,\n",
      "         -8.2863e-03,  5.7433e-02, -2.3889e-02, -3.0241e-02, -3.1015e-02,\n",
      "         -8.4405e-03, -1.5663e-02,  8.3872e-03, -1.7255e-02, -2.6165e-02,\n",
      "          1.9121e-02,  9.6379e-03, -2.9223e-02, -1.0411e-01, -1.0729e-02,\n",
      "          9.5394e-03,  1.0632e-02, -1.6602e-02, -7.3876e-03, -1.6193e-02,\n",
      "         -3.6302e-02, -2.8756e-02, -1.4680e-02, -6.4091e-03, -2.3494e-02,\n",
      "         -1.6208e-02,  4.5371e-03, -2.7083e-02,  1.9857e-02,  3.4151e-02,\n",
      "         -4.8568e-02, -3.9144e-03,  5.9807e-03, -2.8504e-03,  5.4958e-02,\n",
      "         -8.8405e-02, -3.4962e-02,  3.9720e-02, -4.2688e-02, -5.5405e-03,\n",
      "          6.5126e-03, -2.7509e-02, -1.3019e-02, -6.6177e-03,  8.1781e-02,\n",
      "          3.8435e-02, -1.8209e-02,  5.7286e-02, -3.4162e-02, -4.6776e-02,\n",
      "          1.6749e-02,  8.0143e-03, -4.6784e-03,  2.9059e-03, -2.0852e-03,\n",
      "          3.5711e-02,  3.5717e-02, -2.8193e-02, -2.4807e-02,  8.4755e-03,\n",
      "          1.6833e-03,  1.9310e-02,  3.5540e-02,  2.3062e-02,  9.0379e-03,\n",
      "         -1.3879e-02, -2.8788e-02, -1.9126e-02,  2.1747e-02,  2.2403e-02,\n",
      "         -7.6474e-03, -1.6985e-02,  3.6278e-02, -1.4321e-03,  4.3048e-03,\n",
      "          2.5485e-02,  1.2927e-02,  2.3821e-02, -5.1595e-02, -2.3435e-03,\n",
      "          2.6593e-02,  1.2436e-02, -2.7677e-02, -1.0719e-02, -3.7406e-02,\n",
      "         -3.5573e-02, -3.8266e-02, -3.9242e-02,  3.3244e-02,  1.0053e-02,\n",
      "         -2.0620e-03, -1.3366e-02,  1.2255e-02, -5.7727e-02,  8.4387e-02,\n",
      "         -2.1379e-02, -1.3488e-03]], grad_fn=<DivBackward0>), text_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
      "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
      "         [ 1.0047, -0.7407, -0.5721,  ...,  0.8274,  0.1232, -0.9976],\n",
      "         [ 1.6588, -0.8164, -0.5324,  ...,  0.5703,  0.2359, -1.5175]],\n",
      "\n",
      "        [[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
      "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
      "         [-0.1366, -0.4112,  1.4093,  ...,  0.2005,  0.2695, -1.4270],\n",
      "         [ 0.8336,  0.0540,  0.6738,  ...,  0.0231, -0.2196, -0.6519]],\n",
      "\n",
      "        [[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
      "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
      "         [ 1.2078, -0.5825,  1.2983,  ..., -0.1758, -0.0688, -1.7829],\n",
      "         [ 0.0285,  0.1355,  0.2986,  ...,  0.3843, -0.3634, -1.1940]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.6588, -0.8164, -0.5324,  ...,  0.5703,  0.2359, -1.5175],\n",
      "        [ 0.8336,  0.0540,  0.6738,  ...,  0.0231, -0.2196, -0.6519],\n",
      "        [ 0.0285,  0.1355,  0.2986,  ...,  0.3843, -0.3634, -1.1940]],\n",
      "       grad_fn=<IndexBackward0>), hidden_states=None, attentions=None), vision_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 4.3289e-01,  1.1060e-01,  2.1894e-01,  ...,  1.0912e-04,\n",
      "           1.9908e-01, -3.7438e-02],\n",
      "         [ 2.7080e-01, -9.4489e-02, -2.7909e-01,  ..., -2.5772e-01,\n",
      "           3.7564e-01,  3.1941e-01],\n",
      "         [ 2.0264e-01, -6.3721e-02, -4.1508e-01,  ..., -2.1885e-01,\n",
      "           2.4717e-01,  1.8826e-01],\n",
      "         ...,\n",
      "         [ 2.5014e-01,  8.0660e-02, -7.5978e-02,  ..., -2.2196e-01,\n",
      "           4.8651e-01, -2.6005e-02],\n",
      "         [ 2.1750e-01,  7.2913e-04, -2.2040e-01,  ..., -4.2994e-01,\n",
      "          -3.8309e-02,  1.1059e-01],\n",
      "         [ 2.1078e-01,  5.6010e-01,  3.4419e-02,  ..., -4.5881e-01,\n",
      "           2.0282e-01, -2.6634e-04]]], grad_fn=<AddBackward0>), pooler_output=tensor([[ 1.9541e+00,  1.0911e-01,  1.0596e+00,  4.0669e-01,  9.4836e-01,\n",
      "         -1.2971e+00,  2.2198e+00, -2.3840e-01, -7.1704e-01,  1.9183e-01,\n",
      "         -2.2188e-01, -8.2179e-01, -8.3690e-02,  2.7635e-01,  2.7089e-01,\n",
      "          2.4686e-01,  1.5799e+00,  1.7685e+00, -8.3851e-01,  5.1320e-01,\n",
      "          1.3646e-01,  3.3679e-01,  1.4863e+00,  5.0555e-01, -7.5413e-01,\n",
      "          2.3277e-01,  4.2959e-01,  1.1299e-01,  2.0070e-01,  6.9356e-01,\n",
      "          1.7519e+00,  4.2271e-01,  6.2122e-01, -1.9919e+00,  6.6245e-01,\n",
      "         -7.3889e-01, -7.1565e-01, -2.3098e-01,  9.9489e-01, -1.3613e+00,\n",
      "          1.8172e+00,  5.2982e-01,  5.3659e-01,  9.8659e-01, -3.8276e-01,\n",
      "         -1.9515e-01,  5.6455e-01,  5.8241e-01, -2.3137e-01,  9.5130e-01,\n",
      "         -1.0346e+00,  7.1626e-01,  2.1280e+00,  6.8294e-01, -1.0506e+00,\n",
      "          4.4975e-02,  1.0868e+00,  8.3704e-01,  1.6116e-01,  1.9560e-01,\n",
      "          1.5943e-01, -1.0128e+00,  7.9236e-01, -1.7580e-01,  1.1490e+00,\n",
      "          5.8496e-01, -2.7205e-01,  5.0490e-01,  9.0121e-01, -1.1349e+00,\n",
      "          6.7108e-03,  7.5437e-02, -1.1566e+00, -2.6145e-01,  3.8920e-01,\n",
      "         -3.6748e-02,  1.2718e+00,  4.9193e-01,  5.3244e-01,  1.3486e-01,\n",
      "         -1.7646e-01,  2.1276e-01,  3.9042e-01,  1.0170e+00,  1.3643e-01,\n",
      "         -5.9425e-01, -6.7992e-01, -4.3358e-01, -8.0765e-01,  1.0677e+00,\n",
      "         -3.8088e-01,  1.4758e-01,  1.0156e+00, -8.7761e-01,  6.9291e-01,\n",
      "          1.4372e+00, -4.4301e-01, -1.1528e+00, -5.3039e-01,  5.9894e-01,\n",
      "          1.7309e+00,  3.0060e-01, -3.7470e-01, -7.3259e-01,  6.7088e-01,\n",
      "         -1.0479e-01,  6.8895e-01, -8.5349e-01, -1.7379e-01, -3.6577e-01,\n",
      "          1.5490e+00,  9.7932e-01,  1.5218e+00,  1.9759e-01,  9.9987e-01,\n",
      "         -3.1496e-01, -1.5277e-01, -1.7620e+00,  2.5277e+00,  1.6169e+00,\n",
      "          3.0504e-01, -7.3479e-01,  9.6598e-01,  8.3045e-01, -2.3537e+00,\n",
      "          3.8558e-02, -6.5748e-01,  4.2831e-01, -1.4646e+00, -3.0397e-01,\n",
      "         -6.0749e-01, -3.8767e-01,  1.3047e+00,  1.0752e+00, -3.1013e-01,\n",
      "          1.5727e+00, -1.0451e+00,  5.4598e-01, -1.0766e-01, -5.2619e-01,\n",
      "         -7.7271e-01, -3.0375e-01,  1.1265e+00, -3.6558e-01,  6.8036e-01,\n",
      "         -9.7410e-01,  1.3400e+00, -4.9014e-01,  7.4724e-02, -5.8595e-01,\n",
      "          1.3288e+00, -5.8090e-01,  1.4615e+00,  4.3429e-01,  1.1191e+00,\n",
      "          9.1447e-01,  3.9011e-01, -9.2018e-01, -3.7981e-02, -3.0855e-01,\n",
      "          2.9412e-01, -5.7336e-02,  8.0009e-01,  6.2966e-01,  1.2592e+00,\n",
      "          9.9622e-01,  3.7704e-01, -6.8155e-01,  1.1270e+00,  1.4678e+00,\n",
      "          1.3308e+00, -2.9101e-01,  1.0322e+00,  4.3691e-01, -7.8268e-01,\n",
      "         -8.1273e-01, -3.5922e-01, -2.4651e-01, -1.7724e+00,  9.8992e-01,\n",
      "          7.1865e-01, -1.3561e+00, -2.3504e-01, -4.7530e-01,  1.6699e-01,\n",
      "          3.4256e+00, -2.2412e-01,  9.0654e-01,  1.3258e+00, -1.0834e-01,\n",
      "          1.1309e+00,  1.4495e-01,  2.6330e-01,  4.8446e-02,  1.7912e+00,\n",
      "         -4.3190e-02,  4.9695e-01,  1.1748e+00, -3.8718e-01,  2.4797e-01,\n",
      "         -5.5118e-01,  7.5399e-01,  7.4003e-01,  1.2368e-01,  5.9216e-01,\n",
      "          3.0158e-01,  1.0390e-01,  2.9222e-01,  1.1500e-01, -5.4907e-01,\n",
      "         -1.4875e+00, -9.3581e-01, -1.0626e-01, -2.5839e-01, -8.7344e-01,\n",
      "         -6.6440e-01,  8.4162e-01,  8.0398e-03,  1.1175e-01,  1.1921e+00,\n",
      "          2.5911e-01, -3.4837e-01,  6.8747e-01, -3.3434e-01, -1.2295e-02,\n",
      "          2.1478e-01,  6.5029e-01, -7.6868e-01,  3.0676e-01,  5.0970e-01,\n",
      "         -6.0984e-01,  3.5171e-01,  1.7273e+00, -6.7777e-01, -5.0382e-01,\n",
      "          1.9775e-01,  1.0379e+00,  2.3262e-01, -1.6982e+00, -5.2677e-01,\n",
      "          3.1380e-01,  1.0585e+00,  1.0777e+00, -4.2052e-01,  1.0644e+00,\n",
      "          1.1352e+00,  7.8624e-01,  3.7624e-01,  1.2431e+00,  3.3633e-01,\n",
      "          6.9180e-01, -3.1480e-01, -4.6951e-03, -9.0473e-02, -3.3222e-01,\n",
      "         -3.2318e+00, -2.3891e-01,  8.6039e-01, -9.6682e-01,  1.2085e+00,\n",
      "          2.3870e-01,  9.5352e-01,  1.1608e+00,  8.1317e-02,  3.0176e-01,\n",
      "         -3.0182e-01, -1.2101e+00,  8.0591e-01,  2.2874e+00,  1.0133e+00,\n",
      "          1.5192e+00,  6.8907e-02,  4.8056e-01, -1.7184e+00, -1.6299e+00,\n",
      "          6.9671e-04,  5.8387e-01, -9.5095e-01, -7.5612e-01,  3.8493e-01,\n",
      "         -1.3383e-01,  4.3884e-01,  4.9873e-01,  6.5458e-01,  9.4483e-01,\n",
      "          1.1251e-01,  8.6796e-02,  1.0097e+00, -3.5376e-01,  7.5109e-01,\n",
      "         -3.8978e-01,  3.4204e-01, -1.6086e+00,  6.1345e-01,  9.0390e-02,\n",
      "         -6.8620e-02,  2.0405e-01,  3.2896e-01, -4.2278e-02, -1.4210e+00,\n",
      "          8.3440e-03,  6.5530e-01,  1.0355e+00, -3.0385e-01,  9.7593e-01,\n",
      "         -2.7125e-01, -3.0123e-01,  7.6512e-01, -1.0075e-01,  3.0359e+00,\n",
      "         -4.0931e-01, -6.4039e-01, -8.6249e-02,  1.3801e+00, -1.8084e-01,\n",
      "          1.0133e+00, -6.9327e-01,  3.1830e-01,  1.0054e+00,  1.1500e+00,\n",
      "         -3.2861e-01,  1.0567e+00, -1.3273e-01,  7.0251e-01,  1.0185e+00,\n",
      "          6.5800e-01, -2.7115e-01,  1.1944e+00,  2.3053e-01,  1.0687e-01,\n",
      "          1.4592e+00,  8.7669e-01, -7.4009e-01,  3.7957e-01,  1.1948e-01,\n",
      "          3.6141e-01, -7.9616e+00,  1.0840e+00,  1.3752e+00, -1.3370e-01,\n",
      "         -1.9977e-02, -1.0195e+00, -8.6056e-01,  2.5437e+00,  1.3993e-01,\n",
      "         -2.6187e-01, -9.2340e-01, -4.9529e-01, -7.4378e-01,  1.1345e+00,\n",
      "         -2.4492e-01, -8.7838e-01, -1.6422e+00, -6.9383e-01,  8.7848e-01,\n",
      "          6.1488e-01,  6.8868e-02, -2.2036e-01, -1.3727e-01,  8.0291e-01,\n",
      "         -1.1466e+00,  6.1193e-01,  1.6641e+00, -1.1155e+00,  3.8061e-01,\n",
      "          1.4924e+00, -3.6423e-01, -1.2430e+00, -6.8217e-01,  6.4084e-01,\n",
      "          2.0398e-01,  1.8585e+00, -9.6553e-01, -1.3117e+00,  2.8516e-01,\n",
      "         -1.9856e-01,  6.0291e-01, -7.6725e-01, -4.6651e-02,  1.1762e+00,\n",
      "          1.2972e+00, -1.4555e-01,  3.2298e-01,  2.1006e-01,  1.4595e+00,\n",
      "         -1.3018e+00, -5.8819e-01,  5.5038e-01, -1.2799e+00, -4.4094e-01,\n",
      "          4.7782e-01,  1.9265e+00, -5.5961e-01, -4.2136e-01,  1.1638e+00,\n",
      "          3.4500e-01,  1.2110e+00, -5.9229e-01,  9.5711e-01,  4.9951e-01,\n",
      "          1.9812e-02,  1.6401e+00, -1.5427e+00,  1.4878e-01, -3.8725e-01,\n",
      "          4.2396e-01,  4.6818e-01, -2.9436e-01,  3.0685e-01,  1.5149e-01,\n",
      "          4.1119e-01,  5.5534e-02,  4.3227e-01, -1.1820e+00, -6.4253e-01,\n",
      "          4.9533e-01,  5.3257e-01,  7.0328e-01,  3.7221e-02,  3.8077e-01,\n",
      "         -5.1107e-01, -5.1361e-01,  3.0382e-01, -7.3332e-01, -3.7150e-01,\n",
      "         -1.0546e-01,  7.7748e-01,  3.3534e-01,  1.1127e+00,  5.0508e-02,\n",
      "          1.6542e+00,  1.6740e-01, -1.2124e+00,  3.4868e-01, -8.4780e-01,\n",
      "          7.6047e-01,  1.3480e+00,  3.0420e-01,  1.6570e-01,  1.2084e+00,\n",
      "          4.8747e-01, -2.9264e-01,  4.3144e-01,  1.2807e+00,  2.0303e-01,\n",
      "          8.2533e-01, -1.0340e+00,  3.2132e-01, -1.4939e-01,  2.3159e-01,\n",
      "          9.9434e-01,  5.0724e-01, -5.8360e-01,  3.0608e-01, -4.9227e-01,\n",
      "         -1.4359e+00, -9.1865e-01,  7.6697e-01,  9.8445e-01,  1.1747e+00,\n",
      "          2.7770e-01,  8.5853e-01,  1.8875e+00,  2.2405e+00,  8.0830e-02,\n",
      "          3.5325e-01, -7.6295e-01, -6.8757e-01, -1.7190e-01,  1.3286e+00,\n",
      "          4.0606e-01,  1.0786e+00,  8.1406e-01,  7.4654e-01,  8.8902e-01,\n",
      "          6.6035e-01, -3.9617e-01,  8.8783e-01, -5.0163e-01,  1.3000e-01,\n",
      "         -2.7047e-01,  9.0940e-01,  1.3805e-01,  6.4294e-01,  1.9322e+00,\n",
      "          5.4523e-01,  6.6811e-01,  7.9816e-01, -3.0989e-01,  2.8100e-01,\n",
      "         -3.8326e-01, -1.2837e+00,  4.0905e-02,  1.0387e-01,  1.6774e-01,\n",
      "          1.4038e+00,  3.2201e-02, -1.6642e-01,  1.7580e+00,  1.6274e-01,\n",
      "         -1.8573e-01,  2.9721e-01,  1.2860e+00, -9.9171e-02, -2.5585e-01,\n",
      "          8.3313e-01,  1.5534e+00, -3.7639e-01,  3.3760e-01,  1.2373e-01,\n",
      "          3.3308e-02, -3.2615e-01,  2.4362e-01,  3.0936e-02,  6.5449e-01,\n",
      "          6.9777e-01,  5.7506e-01,  1.4458e+00,  1.0475e+00,  5.0977e-01,\n",
      "         -1.4970e+00, -5.7558e-01, -1.4213e-01,  4.1510e-02, -1.7114e+00,\n",
      "          5.4200e-01, -3.5287e-02,  8.6100e-01,  3.9346e-01, -7.1289e-01,\n",
      "          1.1679e+00,  1.6746e+00,  4.1595e-01,  1.4356e+00, -3.2245e-01,\n",
      "         -1.3052e+00, -1.6025e-01,  1.0286e+00, -2.9552e-01, -3.6915e-01,\n",
      "          4.5068e-01, -3.6868e-01,  8.3303e-02, -1.1217e+00,  2.8254e-01,\n",
      "         -4.7691e-01,  1.0331e+00,  4.2072e-01, -7.3368e-02, -3.8519e-01,\n",
      "         -2.9713e-01, -1.4623e+00,  1.1898e+00,  7.2440e-01, -9.3216e-01,\n",
      "         -6.1709e-01,  5.3430e-01,  6.3671e-01,  9.7156e-02,  7.6825e-01,\n",
      "         -6.4155e-01,  4.2071e-01, -1.6983e+00,  1.8381e+00, -6.5448e-01,\n",
      "         -1.6002e+00,  4.0497e-01, -8.2458e-01, -2.1840e-01, -4.2064e-02,\n",
      "         -8.0999e-01,  9.0546e-01,  3.0407e-01, -1.2550e-01,  5.3371e-01,\n",
      "         -6.6152e-02,  7.3382e-02,  9.8212e-01,  6.0015e-01,  2.4951e+00,\n",
      "          8.7723e-01, -9.0393e-02,  1.1967e+00,  5.9767e-01,  1.0566e+00,\n",
      "         -8.6539e-02,  5.1510e-02, -2.1951e-01,  1.0129e+00,  9.7390e-01,\n",
      "          5.2187e-02, -1.4896e+00, -6.3736e-02,  1.1627e+00, -1.2013e+00,\n",
      "          1.3685e+00, -9.7063e-01,  4.3565e-02,  2.1802e-01,  9.2317e-01,\n",
      "          1.1757e+00, -4.2541e-01, -1.1964e+00,  6.4383e-01,  2.2130e+00,\n",
      "         -2.9330e-01,  1.4537e+00,  3.9509e-02, -1.0447e+00, -8.8025e-02,\n",
      "          2.4661e+00,  1.0489e+00,  1.0278e+00, -4.8918e-01,  1.6091e+00,\n",
      "         -1.1857e-02,  6.1944e-01,  5.0131e-01, -2.0450e-01,  1.8630e-02,\n",
      "         -2.7610e-01,  1.1775e-01,  9.3169e-02,  6.1001e-01, -3.5277e+00,\n",
      "          2.7982e+00, -2.9662e-01, -1.1022e+00, -1.3790e+00, -2.1536e+00,\n",
      "          5.6329e-01, -5.7247e-01, -9.7475e-01, -6.3327e-01, -5.7347e-01,\n",
      "          7.9841e-01, -1.7817e+00, -1.2186e+00, -5.9512e-01,  6.6284e-01,\n",
      "          9.9027e-01,  4.0612e-01,  2.2637e-01,  1.2332e+00, -1.0717e-02,\n",
      "         -4.7083e-02, -2.8383e-01, -4.5028e-01, -8.6601e-01, -1.2107e-01,\n",
      "         -7.6876e-01, -1.3596e-01,  1.5938e+00, -9.7460e-01,  2.9541e-03,\n",
      "          6.0473e-01, -9.5148e-02,  9.8095e-01,  2.4493e-01,  9.5007e-01,\n",
      "          2.7350e-01, -4.4868e-01,  6.1453e-01, -3.5259e-01,  7.2783e-01,\n",
      "         -3.0970e-01,  2.3592e+00,  7.1340e-01,  1.9184e-01, -1.2485e+00,\n",
      "         -7.7262e-03,  4.1267e-01, -8.7958e-01, -6.0633e-02,  8.4835e-01,\n",
      "         -5.0884e-01,  2.8929e-01,  1.0301e+00,  2.8894e-01, -5.3745e-01,\n",
      "          2.0355e+00,  7.2452e-01,  6.6077e-01,  3.2730e-01,  8.1831e-01,\n",
      "          5.9929e-01, -6.2230e-01, -9.6392e-01,  7.0080e-01, -6.7791e-02,\n",
      "         -9.4917e-03,  1.0085e+00,  1.2147e+00,  8.7471e-01,  1.7326e-01,\n",
      "          5.1717e-01,  3.7128e-01,  6.1628e-01, -4.7774e-01, -1.4410e-01,\n",
      "          1.5541e+00, -2.5311e-02, -3.3300e-01,  9.5948e-01,  1.2595e+00,\n",
      "         -2.3991e-01,  1.4130e+00,  9.1051e-01,  1.1010e+00, -7.1661e-01,\n",
      "          3.0120e-01, -5.4027e-01, -1.1583e+00,  1.8150e-01,  1.6593e-01,\n",
      "          2.7328e-01,  5.4389e-01, -1.8817e-01,  2.0121e+00, -9.2750e-02,\n",
      "         -6.2269e-01,  1.1340e-02, -7.6688e-01,  2.9801e-01,  7.9462e-01,\n",
      "         -4.8927e-01,  1.3174e+00,  3.1836e-01,  2.7097e+00, -8.8055e-01,\n",
      "          8.3981e-02,  1.0220e+00, -3.3274e-01,  1.0508e+00, -2.9524e-01,\n",
      "          7.9668e-01,  5.8570e-01,  1.6341e-01,  6.7784e-01,  2.3335e-01,\n",
      "          4.4819e-01,  8.6948e-01,  8.7713e-01,  9.1513e-01,  8.0610e-01,\n",
      "          1.0694e+00,  9.1189e-01, -5.9763e-01,  5.4363e-01, -3.0359e-01,\n",
      "          2.1935e-01, -2.9565e-02,  1.2048e+00,  1.9603e+00, -4.5013e-01,\n",
      "          3.9595e-01, -1.3007e-01, -6.1872e-01,  1.1835e+00, -1.7168e-01,\n",
      "          5.5124e-01,  3.6112e-01, -1.1138e+00, -1.1097e+00, -4.7596e-01,\n",
      "         -1.1562e-02,  1.0372e+00,  2.9012e-02]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None))\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
